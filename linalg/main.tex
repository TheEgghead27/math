\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{thmtools}
\usepackage{graphicx} % Required for inserting images

\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\Mat}{Mat}

\declaretheoremstyle[spaceabove=0.25cm,spacebelow=0.25cm,bodyfont=\normalfont,notefont=\normalfont\bfseries, notebraces={(}{)}]{noital}
\declaretheorem[parent=section,style=noital]{theorem, lemma}
%\declaretheorem[parent=theorem]{proof}
\declaretheorem[parent=section,style=noital]{definition}
\declaretheorem[style=remark, numbered=no]{remark}


\title{MATH 2260}
\author{David Chen}
\date{Fall 2025}

\begin{document}

\section{Preliminaries -- Set Theory}
A \textbf{set} is a collection of objects called the \textbf{elements} of the set.\footnote{This is an informal "definition" of a set.}
We can describe a set with either a list of all the elements, or the characteristic properties of a set (e.g. $\left\{1,2,3 \right\} = \left\{ x \in \mathbb{N} \mid x \le 3\right\}$)

$x\in A$ means x is contained in the set A, $x \notin A$ is the opposite. The Principle of Excluded Middle states that these are the only two possible states.

$B \subset A$ if $\forall x \in B, x\in A$.


\subsection{Examples of Sets}
\begin{itemize}
	\item $\mathbb{Z} = \left\{1,2,3,\cdots\right\}$ natural numbers (sometimes $0$ is included as a natural number)
	\item $\mathbb{Z}$ integers
	\item $\mathbb{Q}$ rational numbers
	\item $\mathbb{R}$ real numbers (definitions need real analysis)
	\item $\mathbb{C}$ complex numbers (also needs real analysis)
\end{itemize}

% TODO: CHEATING SHEET CONENT
$f: A \to B$ is injective (into) if $\forall a_1,a_2\in A$  such that $f(a_1)=f(a_2)$, we have $a_1=a_2$.
$f: A \to B$ is surjective (onto) if $\forall b\in B, \exists a \in A$ such that $f(a)=b$ ($\iff f(A) = B$).
$f$ is bijective if it is injective and surjective (one-to-one)

If $f: A\to B$ is bijective, we define $f^{-1}:B\to A$, $b\to f^{-1}(b)$ (TODO FIX THE ARROW), where $f^{-1}(b)$ is the unique element in $A$ such that $f(f^{-1}(b))=b$.

A field is a set $F$ together with two operations (function): $+:F\times F \to F, (a,b) |=> a+b$, $\cdot: F\times F \to F, (a,b) |=> (a\cdot b$ or $(ab)$.

Field condition 1, commutative property (addition and multiplication)
Field condition 2, associative property (addition and multiplication)
Field condition 3, there exists an additive identity element and a multiplicative identity element $1\ne0$.
Field condition 4, there exists an additive inverse element and a multiplicative inverse element
Field condition 5, distributive property

Symmetry on a table (e.g. that for the elements of $\mathbb{F}_2$ under their operations) suggests commutativity.

If $(F, +, \cdot)$ is a field, $K \subset F$ is a subfield if (K, $+\mid_{K\times K}$, $\cdot\mid_{K\times K}$) is a field. We ensure this by checking that the operations' images are contained in the subset and that the identity elements are in the subset (this is redundant, we can also check that we have the inverse elements).

Cancellation Law, $a+c=b+c$, $a=b$, and if $c\ne0$, $ac=bc$ implies $a=b$

Identity elements are unique

$a0=0$, $a(-1)=-a$, $(-1)(-1)=1$

convention: $a+(-b)=a-b$, $a\cdot b^{-1} = \frac{a}{b}$, $a+a+\cdots+a=ak$, $a\cdot a \cdot a \cdot \cdots \cdot a = a^k$ for $k\in\mathbb{Z}$ terms.

The characteristic of a field is $char(F)$ the minimal positive integer $p$ such that $1p=0$.

If such $p$ does not exist, the characteristic is 0. Otherwise, char must be a prime number by the cancellations

if the chararcterisitc is 0, then there is a mapping of the rationals to F, if there is a nonzero characteristic, then there is an isomorphism from $\mathbb{F}_p$ to the field

\section{Vector Spaces}
A vector space over a field $F$ is a set $C$ with $_: V\times V\to V$, $ \cdot: F\times V\to V$. We call elements of $V$ vectors.
Vector condition 1, + commutative
Vector condition 2, + associative

span, linear combination


A linear equation over $F$ of variables $x_1, \cdots, x_n$ is an expression of the form
$a_1x_1+a_2x_2+\cdots+a_nx_n=b$ for some $a_1,a_2,\cdots,a_n,b\in F$. If $b=0$ this is a homogenous system.

We say $S=(s_1,s_2,\cdots,s_n)\in F^n$ is a solution to the equation if $a_1s_1+\cdots+a_ns_n=b$.
The solution space, set of all $S\in F^n | a_1s_1+\cdots+a_ns_n=b0$ is a subspace of $F^n$ for homogenous equations.

A linear system is a set (collection)\footnote{We call it a collection because we only want to w rite half the brackets.} of linear equations). A solution to a linear system is a solution to each equation in the system.

If there is a solution for a linear system, then the solutions of that system are preciely some vector + a solution to the associated homogenous system (i.e. shift by $t$).

$t,t'\in F^n$, both are solutions, then their difference solves the homogenous system.


Invertile operations
The following operations preserve the solution set of a linear system
- interchangin ght eorder of two equations
- multiplying an equation by a nonzdreo element in F (scaling)
- adding a multiplication of an equation to another equation


linear indpeendence exists

unique expression of anay vector in terms of basis


linear system has a unique solution if and only if the homogenous system has a unique solution


\section{3}
\section{Linear Systems}
\begin{definition}
    A solution to a linear system $A=(a_{ij})_{m\times n}\in \Mat_{m\times n}$, $B\in F^m$ is an $x\in F^n$ such that $Ax=b$.
\end{definition}

% TODO: find a normal place for this result
\begin{remark}
    $$(AB)^t = B^tA^t$$
\end{remark}

\subsection{Elementary Matrices}
\begin{definition}
    Elementary matrices represent the three primitive operations:
    \begin{itemize}
        \item Row Interchange: $$\begin{bmatrix}
            1\\
            &\ddots\\
            && 0 & \cdots & 1\\
            && \vdots && \vdots\\
            && 1 & \cdots & 0\\
            &&&&&\ddots\\
            &&&&&&1\\
        \end{bmatrix} \begin{bmatrix}
            a_{11} &\cdots &a_{1n}\\
            \vdots & &\vdots\\
            a_{i1} &\cdots &a_{in}\\
            \vdots & &\vdots\\
            a_{j1} &\cdots &a_{jn}\\
            \vdots & &\vdots\\
            a_{m1} &\cdots &a_{mn}\\
        \end{bmatrix}=
        \begin{bmatrix}
            a_{11} &\cdots &a_{1n}\\
            \vdots & &\vdots\\
            a_{j1} &\cdots &a_{jn}\\
            \vdots & &\vdots\\
            a_{i1} &\cdots &a_{in}\\
            \vdots & &\vdots\\
            a_{m1} &\cdots &a_{mn}\\
        \end{bmatrix}
        $$
        The inverse of a row interchange is the same row interchange applied again. This matrix serves as a column interchange if used as the second matrix multiplication argument.
        \item Arbitrary Row Multiplication:
    \end{itemize}
\end{definition}

\section{Diagonalization}
Suppose $V$ is a vector space over $F$ of dimension $n$. For a linear transformation $T: V\to V$, can we find a basis $v_1,v_2,\cdots,v_n$ such that the matrix associated to $T$ looks ``simple''?

\begin{definition}
We say $T$ is diagonalizable of $\exists$ a basis $\left\{v_1,v_2,\cdots,v_n\right\}$ such that $$\begin{bmatrix}
    T(v_1) & T(v_2) & \cdots & T(v_n)
\end{bmatrix} = \begin{bmatrix}
    v_1 & v_2 & \cdots & v_n
\end{bmatrix}\begin{bmatrix}
    \lambda_1 & 0 & \cdots & 0\\
    0 & \lambda_2 & \cdots & 0\\
    \vdots & \vdots &  \ddots & \vdots \\
    0 & 0 & \cdots & \lambda_n
\end{bmatrix}$$$$T(v_j)=\lambda_jv_j$$
\end{definition}

\begin{definition}
    We say $\lambda\in F$ is an eigenvalue of $T$ if $\exists v\in V \setminus\left\{0\right\}$ such that $T(v)=\lambda v$. We call $v$ an eigenvector associated to the eigenvalue $\lambda$.
\end{definition}

\begin{remark}
    Since $T(v)-\lambda v = 0 = T(v) - \lambda \id{v} = (T-\lambda\id)(v)=0$, we have that the function $(T-\lambda\id)\in\Hom{(V,V)}$ has $v$ in its kernel. Thus, for the right value of $\lambda$, the function is not injective, surjective, or invertible, and the associated matrix multiplication $(A-\lambda I)(v)=0$ and $\det{(A-\lambda I)}=0$.
\end{remark}
\end{document}

